{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean / Median imputation\n",
    "\n",
    "Imputation is the act of replacing missing data with statistical estimates of the missing values. The goal of any imputation technique is to produce a **complete dataset** that can be used to train machine learning models.\n",
    "\n",
    "Mean / median imputation consists of replacing all occurrences of missing values (NA) within a variable by the mean (if the variable has a Gaussian distribution) or median (if the variable has a skewed distribution).\n",
    "\n",
    "**Note the following**:\n",
    "\n",
    "- If a variable is normally distributed, the mean, median and mode, are approximately the same. Therefore, replacing missing values by the mean and the median are equivalent. Replacing missing data by the mode is not common practice for  numerical variables.\n",
    "- If the variable is skewed, the mean is biased by the values at the far end of the distribution. Therefore, the median is a better representation of the majority of the values in the variable.\n",
    "- For discrete variables casted as 'int' (to save memory), the mean may not be an integer, therefore the whole variable will be re-casted as 'float'. In order to avoid this behaviour, we can replace NA with the median instead. The median will inevitably be an integer / discrete value as well.\n",
    "\n",
    "============================================\n",
    "\n",
    "In this recipe, we will replace missing values by the median or the mean using pandas, Scikit-learn and Feature-Engine, all open source Python libraries.\n",
    "\n",
    "============================================\n",
    "\n",
    "To download the House Prices dataset from kaggle visit [this website](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data) and download the train.csv file. Rename it to houseprice.csv and save it to the parent folder of your notebook folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean / median imputation with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# to split the datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are going to use only the following variables:\n",
    "\n",
    "cols_to_use =  ['LotFrontage', 'MasVnrArea', 'GarageYrBlt', 'SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LotFrontage  MasVnrArea  GarageYrBlt  SalePrice\n",
       "0         65.0       196.0       2003.0     208500\n",
       "1         80.0         0.0       1976.0     181500\n",
       "2         68.0       162.0       2001.0     223500\n",
       "3         60.0         0.0       1998.0     140000\n",
       "4         84.0       350.0       2000.0     250000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's load the House Prices dataset\n",
    "\n",
    "data = pd.read_csv('../houseprice.csv', usecols=cols_to_use)\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1022, 4), (438, 4))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's separate into training and testing set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data,\n",
    "                                                    data['SalePrice'],\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=0)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LotFrontage    0.184932\n",
       "MasVnrArea     0.004892\n",
       "GarageYrBlt    0.052838\n",
       "SalePrice      0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the percentage of missing data within those variables\n",
    "# same code as we learnt in section 3 on variable characteristics\n",
    "\n",
    "X_train.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's make a function to fill missing values with the mean or median:\n",
    "# the variable takes the dataframe, the variable, and the value of the\n",
    "# mean or median\n",
    "\n",
    "# and returns the variable with the filled na\n",
    "\n",
    "\n",
    "def impute_na(df, variable, value):\n",
    "\n",
    "    return df[variable].fillna(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sole\\Anaconda3\\envs\\feml\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "# replace the missing values with the value\n",
    "\n",
    "value = X_train['LotFrontage'].median()\n",
    "\n",
    "X_train.loc[:,'LotFrontage'] = impute_na(X_train, 'LotFrontage', value)\n",
    "X_test.loc[:,'LotFrontage'] = impute_na(X_test, 'LotFrontage', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and we repeat for the other 2 variables\n",
    "value = X_train['MasVnrArea'].median()\n",
    "\n",
    "X_train.loc[:,'MasVnrArea'] = impute_na(X_train, 'MasVnrArea', value)\n",
    "X_test.loc[:,'MasVnrArea'] = impute_na(X_test, 'MasVnrArea', value)\n",
    "\n",
    "value = X_train['GarageYrBlt'].median()\n",
    "\n",
    "X_train.loc[:, 'GarageYrBlt'] = impute_na(X_train, 'GarageYrBlt', value)\n",
    "X_test.loc[:,'GarageYrBlt'] = impute_na(X_test, 'GarageYrBlt', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sole\\Anaconda3\\envs\\feml\\lib\\site-packages\\pandas\\core\\indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n"
     ]
    }
   ],
   "source": [
    "# if instead I would like to replace by the value this is what I do:\n",
    "\n",
    "value = X_train['LotFrontage'].mean()\n",
    "\n",
    "X_train.loc[:,'LotFrontage_value'] = impute_na(X_train, 'LotFrontage', value)\n",
    "X_test.loc[:,'LotFrontage_value'] = impute_na(X_test, 'LotFrontage', value)\n",
    "\n",
    "value = X_train['MasVnrArea'].mean()\n",
    "\n",
    "X_train.loc[:,'MasVnrArea'] = impute_na(X_train, 'MasVnrArea', value)\n",
    "X_test.loc[:,'MasVnrArea'] = impute_na(X_test, 'MasVnrArea', value)\n",
    "\n",
    "value = X_train['GarageYrBlt'].mean()\n",
    "\n",
    "X_train.loc[:, 'GarageYrBlt'] = impute_na(X_train, 'GarageYrBlt', value)\n",
    "X_test.loc[:,'GarageYrBlt'] = impute_na(X_test, 'GarageYrBlt', value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean / median imputation with Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# these are the packages we need to impute missing data\n",
    "# with sklearn\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# to split the datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's load the House Prices dataset\n",
    "\n",
    "data = pd.read_csv('../houseprice.csv', usecols=cols_to_use)\n",
    "\n",
    "# let's separate into training and testing set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data,\n",
    "                                                    data['SalePrice'],\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.900e+01, 0.000e+00, 1.979e+03, 1.630e+05])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we impute the missing values with SimpleImputer\n",
    "\n",
    "# create an instance of the simple imputer\n",
    "# we indicate that we want to impute with the median\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "# we fit the imputer to the train set\n",
    "# the imputer will learn the median of all variables\n",
    "imputer.fit(X_train)\n",
    "\n",
    "# we can look at the learnt medians like this:\n",
    "imputer.statistics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and now we impute the train and test set\n",
    "\n",
    "# NOTE: the data is returned as a numpy array!!!\n",
    "X_train = imputer.transform(X_train)\n",
    "X_test = imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean / median imputation selecting features to impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# these are the packages we need to impute missing data\n",
    "# with sklearn\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# to split the datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's load the House Prices dataset\n",
    "\n",
    "data = pd.read_csv('../houseprice.csv', usecols=cols_to_use)\n",
    "\n",
    "# let's separate into training and testing set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data,\n",
    "                                                    data['SalePrice'],\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we need to make lists, indicating which features\n",
    "# will be imputed with each method\n",
    "\n",
    "numeric_features_mean = ['LotFrontage']\n",
    "numeric_features_median = ['MasVnrArea', 'GarageYrBlt']\n",
    "\n",
    "# then we instantiate the imputers, within a pipeline\n",
    "# we create one mean imputer and one median imputer\n",
    "# by changing the parameter in the strategy\n",
    "\n",
    "numeric_mean_imputer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "])\n",
    "\n",
    "numeric_median_imputer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "])\n",
    "\n",
    "# then we put the features list and the transformers together\n",
    "# using the column transformer\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('mean_imputer', numeric_mean_imputer, numeric_features_mean),\n",
    "    ('median_imputer', numeric_median_imputer, numeric_features_median)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "         transformer_weights=None,\n",
       "         transformers=[('mean_imputer', Pipeline(memory=None,\n",
       "     steps=[('imputer', SimpleImputer(copy=True, fill_value=None, missing_values=nan, strategy='mean',\n",
       "       verbose=0))]), ['LotFrontage']), ('median_imputer', Pipeline(memory=None,\n",
       "     steps=[('imputer', SimpleImputer(copy=True, fill_value=None, missing_values=nan,\n",
       "       strategy='median', verbose=0))]), ['MasVnrArea', 'GarageYrBlt'])])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we fit the preprocessor\n",
    "preprocessor.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and now we can impute the data\n",
    "X_train = preprocessor.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  69.66866747,  573.        , 1998.        ],\n",
       "       [  69.66866747,    0.        , 1996.        ],\n",
       "       [  50.        ,    0.        , 1979.        ],\n",
       "       ...,\n",
       "       [  68.        ,    0.        , 1978.        ],\n",
       "       [  69.66866747,   18.        , 2003.        ],\n",
       "       [  58.        ,   30.        , 1998.        ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# be carefutl that Scikit-Learn transformers return NumPy arrays!!\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean / Median imputation with feature engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from feature_engine import missing_data_imputers as mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's load the House Prices dataset\n",
    "\n",
    "data = pd.read_csv('../houseprice.csv', usecols=cols_to_use)\n",
    "\n",
    "# let's separate into training and testing set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data,\n",
    "                                                    data['SalePrice'],\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MeanMedianImputer(imputation_method='median',\n",
       "         variables=['LotFrontage', 'MasVnrArea', 'GarageYrBlt'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_imputer = mi.MeanMedianImputer(\n",
    "    imputation_method='median',\n",
    "    variables=['LotFrontage', 'MasVnrArea', 'GarageYrBlt'])\n",
    "\n",
    "median_imputer.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LotFrontage': 69.0, 'MasVnrArea': 0.0, 'GarageYrBlt': 1979.0}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dictionary with the mappings for each variable\n",
    "median_imputer.imputer_dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the data\n",
    "X_train = median_imputer.transform(X_train)\n",
    "X_test = median_imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LotFrontage    0.0\n",
       "MasVnrArea     0.0\n",
       "GarageYrBlt    0.0\n",
       "SalePrice      0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "feml",
   "language": "python",
   "name": "feml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
